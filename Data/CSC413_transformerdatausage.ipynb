{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "BUdqkQRDtmY-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681513968644,
     "user_tz": 240,
     "elapsed": 1104,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    },
    "ExecuteTime": {
     "start_time": "2023-04-16T15:47:49.619368Z",
     "end_time": "2023-04-16T15:47:52.783745Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle, os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JioNcY4ctmZA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512363957,
     "user_tz": 240,
     "elapsed": 10,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    },
    "outputId": "ae798593-bd9c-4e7d-cfbc-df82988ade6b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHVxGIqctmZB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512363958,
     "user_tz": 240,
     "elapsed": 10,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    },
    "outputId": "7e5e61ce-546b-4417-9f29-9a3b4a8e897f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. data preparation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "EMk0h6n_tmZC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_2015 = pd.read_csv('data/2015.csv')\n",
    "data_2016 = pd.read_csv('data/2016.csv')\n",
    "data_2017 = pd.read_csv('data/2017.csv')\n",
    "data_2018 = pd.read_csv('data/2018.csv')\n",
    "data_2019 = pd.read_csv('data/2019.csv')\n",
    "data_2020 = pd.read_csv('data/2020.csv')\n",
    "data_2021 = pd.read_csv('data/2021.csv')\n",
    "data_2022 = pd.read_csv('data/2022.csv')"
   ],
   "metadata": {
    "id": "d1tPXOOluL8Z",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512363958,
     "user_tz": 240,
     "elapsed": 8,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#load date to train, valid and test\n",
    "train_df = pd.concat([data_2015, data_2016, data_2017, data_2018, data_2019], axis=0, ignore_index=True)\n",
    "valid_df = pd.concat([data_2020, data_2021], axis=0, ignore_index=True)\n",
    "test_df = data_2022"
   ],
   "metadata": {
    "id": "rftk2t7XtmZC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512363958,
     "user_tz": 240,
     "elapsed": 8,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#chec the date in df which have more than 3 missising\n",
    "flab = ['Temp Flag', 'Rel Hum Flag', 'Dew Point Temp Flag', 'Precip. Amount Flag', 'Stn Press Flag', 'Wind Spd Flag']\n",
    "print(\"----------------------tain--------------------------\")\n",
    "date_t = set()\n",
    "for i in flab:\n",
    "  count1 = train_df[train_df[i] == 'M'].groupby(['Year', 'Month', 'Day'])[i].count()\n",
    "  count1 = count1[count1 > 3]\n",
    "  for j in count1.keys():\n",
    "    date_t.add(j)\n",
    "print(date_t)\n",
    "print(\"----------------------vali--------------------------\")\n",
    "date_v = set()\n",
    "for i in flab:\n",
    "  count1 = valid_df[valid_df[i] == 'M'].groupby(['Year', 'Month', 'Day'])[i].count()\n",
    "  count1 = count1[count1 > 3]\n",
    "  for j in count1.keys():\n",
    "    date_v.add(j)\n",
    "print(date_v)\n",
    "print(\"----------------------test--------------------------\")\n",
    "date_s = set()\n",
    "for i in flab:\n",
    "  count1 = test_df[test_df[i] == 'M'].groupby(['Year', 'Month', 'Day'])[i].count()\n",
    "  count1 = count1[count1 > 3]\n",
    "  for j in count1.keys():\n",
    "    date_s.add(j)\n",
    "print(date_s)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTqu4OzAOkeA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512363958,
     "user_tz": 240,
     "elapsed": 8,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    },
    "outputId": "5d967d94-4d29-403d-dc8f-69417c9685a7"
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------tain--------------------------\n",
      "{(2019, 6, 5), (2019, 6, 2), (2019, 5, 24), (2015, 12, 10), (2015, 4, 6), (2015, 12, 13), (2015, 12, 7), (2015, 11, 5), (2019, 6, 1), (2019, 6, 4), (2019, 6, 19), (2019, 5, 17), (2015, 12, 6), (2015, 12, 12), (2019, 5, 23), (2015, 12, 9), (2015, 11, 4), (2019, 6, 3), (2019, 6, 18), (2016, 12, 19), (2015, 12, 14)}\n",
      "----------------------vali--------------------------\n",
      "{(2021, 7, 21), (2020, 1, 14), (2021, 7, 30), (2021, 7, 20), (2021, 2, 9)}\n",
      "----------------------test--------------------------\n",
      "{(2022, 5, 13), (2022, 7, 10), (2022, 7, 13), (2022, 5, 28), (2022, 7, 19), (2022, 5, 22), (2022, 5, 25), (2022, 5, 31), (2022, 5, 12), (2022, 7, 9), (2022, 5, 9), (2022, 7, 6), (2022, 5, 21), (2022, 7, 12), (2022, 5, 24), (2022, 7, 21), (2022, 5, 27), (2022, 7, 18), (2022, 5, 30), (2022, 7, 5), (2022, 5, 11), (2022, 7, 8), (2022, 7, 14), (2022, 5, 20), (2022, 5, 26), (2022, 5, 23), (2022, 7, 20), (2022, 5, 29), (2022, 5, 10), (2022, 7, 7)}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#remove the day which have 3 more missing data in train datafram\n",
    "for i in date_t:\n",
    "  train_df = train_df[~((train_df['Year'] == i[0]) & (train_df['Month'] == i[1]) & (train_df['Day'] == i[2]))]\n",
    "train_df.dropna(how='all')\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "#remove the day which have 3 more missing data in valid datafram\n",
    "for i in date_v:\n",
    "  valid_df = valid_df[~((valid_df['Year'] == i[0]) & (valid_df['Month'] == i[1]) & (valid_df['Day'] == i[2]))]\n",
    "valid_df.dropna(how='all')\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "#remove the day which have 3 more missing data in test datafram\n",
    "for i in date_s:\n",
    "  test_df = test_df[~((test_df['Year'] == i[0]) & (test_df['Month'] == i[1]) & (test_df['Day'] == i[2]))]\n",
    "test_df.dropna(how='all')\n",
    "test_df = test_df.reset_index(drop=True)"
   ],
   "metadata": {
    "id": "PtSo9P5yqvb3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512363959,
     "user_tz": 240,
     "elapsed": 8,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#replace the missing data with the average of last and next hour\n",
    "flab = ['Temp Flag', 'Dew Point Temp Flag', 'Rel Hum Flag', 'Precip. Amount Flag', 'Wind Spd Flag', 'Stn Press Flag', 'Visibility Flag']\n",
    "vlab = ['Temp (°C)', \"Dew Point Temp (°C)\", \"Rel Hum (%)\", \"Precip. Amount (mm)\", \"Wind Spd (km/h)\", \"Stn Press (kPa)\", \"Visibility (km)\"]\n",
    "idx = 0\n",
    "for i in flab:\n",
    "  rows = train_df.loc[train_df[i] == 'M']\n",
    "  for index, row in rows.iterrows():\n",
    "    train_df.loc[index, vlab[idx]] = (\n",
    "            ((train_df.loc[index - 1, vlab[idx]]) + train_df.loc[index + 1, vlab[idx]]) / 2)\n",
    "  idx += 1\n",
    "#replace the missing data in valid set\n",
    "idx = 0\n",
    "for i in flab:\n",
    "  rows = valid_df.loc[valid_df[i] == 'M']\n",
    "  for index, row in rows.iterrows():\n",
    "    valid_df.loc[index, vlab[idx]] = (\n",
    "            ((valid_df.loc[index - 1, vlab[idx]]) + valid_df.loc[index + 1, vlab[idx]]) / 2)\n",
    "  idx += 1\n",
    "#replace the missing data in test set\n",
    "idx = 0\n",
    "for i in flab:\n",
    "  rows = test_df.loc[test_df[i] == 'M']\n",
    "  for index, row in rows.iterrows():\n",
    "    test_df.loc[index, vlab[idx]] = (\n",
    "            ((test_df.loc[index - 1, vlab[idx]]) + test_df.loc[index + 1, vlab[idx]]) / 2)\n",
    "  idx += 1"
   ],
   "metadata": {
    "id": "1iV3dQLXtNYG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512363959,
     "user_tz": 240,
     "elapsed": 8,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# chose the train data that need to used\n",
    "labx = [\"Temp (°C)\", \"Dew Point Temp (°C)\", \"Rel Hum (%)\", \"Precip. Amount (mm)\", \"Wind Spd (km/h)\", \"Stn Press (kPa)\", \"Visibility (km)\"]\n",
    "temp = pd.DataFrame(columns=labx)\n",
    "for j in labx:\n",
    "  temp[j] = train_df[j]\n",
    "train_data = temp\n",
    "# chose the valid data that need to used\n",
    "temp = pd.DataFrame(columns=labx)\n",
    "for j in labx:\n",
    "  temp[j] = valid_df[j]\n",
    "valid_data = temp\n",
    "# chose the test data that need to used\n",
    "temp = pd.DataFrame(columns=labx)\n",
    "for j in labx:\n",
    "  temp[j] = test_df[j]\n",
    "test_data = temp\n",
    "\n",
    "# drop the row that contain None\n",
    "train_data = train_data.dropna()\n",
    "valid_data = valid_data.dropna()\n",
    "test_data = test_data.dropna()"
   ],
   "metadata": {
    "id": "qIKupqEJxm9P",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512363959,
     "user_tz": 240,
     "elapsed": 7,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    }
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values: 26\n",
      "Unique values: [nan 'Snow' 'Rain,Fog' 'Fog' 'Haze' 'Rain' 'Freezing Rain,Fog'\n",
      " 'Freezing Rain,Snow' 'Snow,Blowing Snow' 'Thunderstorms,Rain,Fog'\n",
      " 'Thunderstorms,Rain' 'Thunderstorms,Heavy Rain,Fog' 'Moderate Rain,Fog'\n",
      " 'Heavy Rain' 'Thunderstorms' 'Heavy Rain,Fog' 'Moderate Rain' 'Rain,Snow'\n",
      " 'Freezing Rain' 'Thunderstorms,Fog' 'Thunderstorms,Moderate Rain'\n",
      " 'Thunderstorms,Haze' 'Thunderstorms,Heavy Rain' 'Moderate Snow'\n",
      " 'Heavy Snow' 'Thunderstorms,Moderate Rain,Fog' 'Haze,Blowing Snow']\n",
      "Number of unique values: 20\n",
      "Unique values: [nan 'Snow' 'Rain' 'Rain,Snow' 'Fog' 'Rain,Fog' 'Heavy Rain,Fog'\n",
      " 'Moderate Rain,Fog' 'Moderate Rain' 'Freezing Rain,Snow' 'Haze'\n",
      " 'Thunderstorms,Moderate Rain' 'Thunderstorms,Heavy Rain' 'Thunderstorms'\n",
      " 'Thunderstorms,Rain,Fog' 'Thunderstorms,Rain' 'Thunderstorms,Fog'\n",
      " 'Moderate Snow' 'Heavy Snow' 'Thunderstorms,Moderate Rain,Fog'\n",
      " 'Thunderstorms,Heavy Rain,Fog']\n",
      "20\n",
      "Number of unique values: 16\n",
      "Unique values: ['Fog' nan 'Rain,Fog' 'Snow' 'Rain' 'Moderate Snow' 'Heavy Snow'\n",
      " 'Freezing Rain,Snow' 'Rain,Snow' 'Haze' 'Moderate Rain,Fog'\n",
      " 'Thunderstorms' 'Thunderstorms,Rain' 'Heavy Rain,Fog'\n",
      " 'Thunderstorms,Rain,Fog' 'Moderate Rain' 'Snow,Blowing Snow']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "#Change weather name from string to number\n",
    "lab_weather = [\"Temp (°C)\", \"Dew Point Temp (°C)\", \"Rel Hum (%)\", \"Precip. Amount (mm)\", \"Wind Spd (km/h)\", \"Stn Press (kPa)\", \"Visibility (km)\", \"Weather\"]\n",
    "temp1 = pd.DataFrame(columns=lab_weather)\n",
    "for j in lab_weather:\n",
    "    temp1[j] = train_df[j]\n",
    "unique_count = temp1[\"Weather\"].nunique()\n",
    "print(\"Number of unique values:\", unique_count)\n",
    "unique_values = temp1[\"Weather\"].unique()\n",
    "print(\"Unique values:\", unique_values)\n",
    "temp1[\"Weather\"] = temp1[\"Weather\"].fillna(0)\n",
    "weather = []\n",
    "for i in unique_values:\n",
    "    weather.append(i)\n",
    "weather.pop(0)\n",
    "replacement_dict = {\n",
    "    'Snow':1,\n",
    "    'Rain,Fog':2,\n",
    "    'Fog':3,\n",
    "    'Haze':4,\n",
    "    'Rain':5,\n",
    "    'Freezing Rain,Fog':6,\n",
    "    'Freezing Rain,Snow':7,\n",
    "    'Snow,Blowing Snow':8,\n",
    "    'Thunderstorms,Rain,Fog':9,\n",
    "    'Thunderstorms,Rain':10,\n",
    "    'Thunderstorms,Heavy Rain,Fog':11,\n",
    "    'Moderate Rain,Fog':12,\n",
    "    'Heavy Rain':13,\n",
    "    'Thunderstorms':14,\n",
    "    'Heavy Rain,Fog':15,\n",
    "    'Moderate Rain':16,\n",
    "    'Rain,Snow':17,\n",
    "    'Freezing Rain':18,\n",
    "    'Thunderstorms,Fog':19,\n",
    "    'Thunderstorms,Moderate Rain':20,\n",
    "    'Thunderstorms,Haze':21,\n",
    "    'Thunderstorms,Heavy Rain':22,\n",
    "    'Moderate Snow':23,\n",
    "    'Heavy Snow':24,\n",
    "    'Thunderstorms,Moderate Rain,Fog':25,\n",
    "    'Haze,Blowing Snow':26\n",
    "}\n",
    "temp2 = pd.DataFrame(columns=lab_weather)\n",
    "for j in lab_weather:\n",
    "    temp2[j] = valid_df[j]\n",
    "unique_count1 = temp2[\"Weather\"].nunique()\n",
    "print(\"Number of unique values:\", unique_count1)\n",
    "unique_values1 = temp2[\"Weather\"].unique()\n",
    "print(\"Unique values:\", unique_values1)\n",
    "temp2[\"Weather\"] = temp2[\"Weather\"].fillna(0)\n",
    "weather1 = []\n",
    "for i in unique_values1:\n",
    "    weather1.append(i)\n",
    "weather1.pop(0)\n",
    "print(len(list(set(weather) & set(weather1))))\n",
    "\n",
    "temp3 = pd.DataFrame(columns=lab_weather)\n",
    "for j in lab_weather:\n",
    "    temp3[j] = test_df[j]\n",
    "unique_count2 = temp3[\"Weather\"].nunique()\n",
    "print(\"Number of unique values:\", unique_count2)\n",
    "unique_values2 = temp3[\"Weather\"].unique()\n",
    "print(\"Unique values:\", unique_values2)\n",
    "temp3[\"Weather\"] = temp3[\"Weather\"].fillna(0)\n",
    "weather2 = []\n",
    "for i in unique_values2:\n",
    "    weather2.append(i)\n",
    "weather2.pop(0)\n",
    "print(len(list(set(weather) & set(weather2))))\n",
    "\n",
    "\n",
    "temp1[\"Weather\"] = temp1[\"Weather\"].replace(replacement_dict)\n",
    "temp2[\"Weather\"] = temp2[\"Weather\"].replace(replacement_dict)\n",
    "temp3[\"Weather\"] = temp3[\"Weather\"].replace(replacement_dict)\n",
    "train_data1 = temp1\n",
    "valid_data1 = temp2\n",
    "test_data1 = temp3\n",
    "\n",
    "train_data1 = train_data1.dropna()\n",
    "valid_data1 = valid_data1.dropna()\n",
    "test_data1 = test_data1.dropna()\n",
    "\n",
    "train_data1.to_csv('train_data1.csv', index=False)\n",
    "valid_data1.to_csv('valid_data1.csv', index=False)\n",
    "test_data1.to_csv('test_data1.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "1el2s1Rgy7FX24o_rO1Hg9vIeck_plia0",
     "timestamp": 1680570556286
    }
   ],
   "toc_visible": true
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
